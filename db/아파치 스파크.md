# 아파치 스파크

아파치 스파크를 한 마디로 정의하자면, "빅데이터 처리를 위한 오픈소스 분산 처리 플랫폼", 또는 "빅데이터 분산 처리 엔진" 정도로 표현할 수 있다.

여기서 빅 데이터는 "기존 데이터베이스 관리도구의 능력을 넘어서는 대량 의 정형 또는 심지어 데이터베이스 형태가 아닌 비정형의 데이터 집합조차 포함한 데이터로부터 가치를 추출하고 결과를 분석하는 기술"로 정의할 수 있다.

기존에는 정형 데이터를 RDBMS를 사용하여 큐잉, 샤딩(Hash를 사용한 DB 분산) 등의 방법으로 처리하는 방식에서 데이터가 급격하게 증대함에 따라 사진, 동영상 등을 포함하여 N TB/s 이상의 대용량의 다양한 데이터를 고속으로 처리해야 되는 환경에 직면하였는데, 이를 효율적으로 처리하기위해 등장한 것이 "빅데이터 분산처리 플랫폼"이다.

빅데이터의 수집부터 저장, 처리, 관리까지의 항목은 아래와 같이 나열할 수 있는데, 아파치 스파크는 '빅데이터 처리'부를 용이하게 작업하기 위한 플랫폼이다.

![빅데이터 플랫폼](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2gbSZ%2FbtqIl9fIBWB%2FSZOkxbt5e1sohVJH2wIArK%2Fimg.jpg)

## Apache Spark(아파치 스파크)의 등장

![하둡](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKtOP4%2FbtqIhte63my%2FWR2RA9GvbrH28utlw9yyyk%2Fimg.jpg)

빅데이터의 개념이 등장하였을 당시, "빅데이터 처리 = 하둡(Hadoop)"이라고 할 정도로, 하둡 에코시스템이 시장을 지배하였다. 하둡은 HDFS(Hadoop Distributed File System)라고 불리는, 분산형 파일 시스템을 기반으로 만들어졌다.데이터 처리 시, HDFS와 '맵리듀스'라고 불리는 대형 데이터셋 병렬 처리 방식에 의해 동작한다.

문제는 하둡의 HDFS가 DISK I/O를 기반으로 동작한다는 것에 있었다.실시간성 데이터에 대한 니즈(NEEDS)가 급격하게 증가하면서, 하둡으로 처리하기에는 속도 측면에서 부적합한 시나리오들이 등장하기 시작하였다.

이 때 등장한 것이 아파치 스파크로, 아파치 스파크는 인메모리상에서 동작하기 때문에, 반복적인 처리가 필요한 작업에서 속도가 하둡보다 최소 1000배 이상 빠르며, 이를 통해 데이터 실시간 스트리밍 처리라는 니즈를 충족함으로써, 빅데이터 프레임워크 시장을 빠르게 잠식해가고 있다.

최근에는 '하둡 + 스파크'라는 둘의 연계가 하나의 큰 흐름으로 자리잡혔으며, 하둡의 YARN 위에 스파크를 얹고, 실시간성이 필요한 데이터는 스파크로 처리하는 방식으로,대부분의 기업들과 연구단체에서 이와 같은 아키텍처를 구성하여 동작 중에 있다.

## 스파크의 구조

![스파크의 구조](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHKJmf%2FbtqH8dquDKR%2FbeVcKK2PEMAz9Ktye4Okuk%2Fimg.png)

아파치 스파크는 위와 같이 다양한 컴포넌트와 라이브러리를 지원한다.기본적으로 Scala, JAVA, Pyhon 등의 다양한 언어 기반의 고수준 API를 사용 가능하다.

더 나아가, SQL의 기능을 담당하는 Spark SQL, 실시간 데이터 처리를 지원하는 Spark Streaming, 여러 머신러닝 기법을 지원하는 MLlib 등 다양하고 넓은 범위의 라이브러리가 있으며, 지속적으로 확장되어 가고 있다.

![Spark Steaming](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcUpP3L%2FbtqIdUYzcNU%2F52vxTuop2G5wQVQkdlJA11%2Fimg.png)

특히, Spark Streaming은 Kafka, Hadoop과 연계 가능한 스파크의 확장성 덕분에, 위와 같은 구조로 대부분의 기업에서 활용되고 있다. 카프카, 플럼, 키네시스, TCP 소켓 등 다양한 경로를 통해서 데이터를 입력 받고, map, reduce, window 등의 연산을 통해 데이터를 분석하여 최종적으로 파일시스템, 데이터베이스 등에 적재된다.

> 출처
>
> - https://artist-developer.tistory.com/7
