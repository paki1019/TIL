# 데이터 파이프라인(Data Pipeline)
데이터를 한 장소에서 다른 장소로 차례대로 전달하는, 데이터로 구성된 일련의 시스템
![데이터 파이프라인(Data Pipeline)](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcLsFHk%2FbtqZ1IM3Idj%2FCC4FKEyRzzIhq7IdW1Hd1K%2Fimg.png)

## 1) 데이터 수집
데이터 파이프라인은 데이터를 모으는 것에서부터 시작. 데이터의 전송은 다음과 같이 크게 두 가지 형태로 구분할 수 있음.

- Bulk Type: 벌크형은 이미 존재하는 데이터를 정리해 추출하는 방법으로 DB와 파일 서버 등 정기적으로 데이터를 수집하는 형태
- Streaming Type: 스트리밍형은 차례차례 생성되는 데이터를 끊임없이 보내는 방법으로 Mobile App이나 Embedded 장비 등에서 데이터를 수집하는 형태

## 2) Stream and Batch Process
수집한 데이터를 저장하기 전에 처리하는 과정. 빅데이터 이전부터 유효하게 활용되었던 기술은 '배치(batch) 위주의 기술'이었습니다. 매일 적재되는 데이터 기준, 새벽에 전 날 데이터의 실적 등을 정리하는 형태. 배치 프로세스는 물론 현재도 유효하게 적용되지만, 빅데이터 기술에서는 실시간 데이터를 쌓아서 실시간에 가까운 실적 등의 추세를 파악할 수 있게 하는 '스트림(stream) 처리'가 주류가 되고 있음.

## 3) Distributed Storage(분산 스토리지)
수집과 처리가 된 데이터는 '분산 스토리지(저장소)'에 저장됨. 대표적으로 Object Storage로 AWS에서 서비스되는 S3 서비스. 또는 NoSQL DB를 분산 스토리지로 활용할 수 있음. HDFS도 이러한 분산 스토리지 중 하나로 Hadoop이라는 대표성을 가지고 있음.

## 4) Distribute Data Processing(분산 데이터 처리)
분산 스토리지에 저장된 데이터를 처리하는 데는 '분산 데이터 처리'가 필요함. 가장 대표적인 분산 처리 프레임워크로는 MapReduce가 있지만 대다수의 분석가 혹은 개발자가 MR을 통해 데이터 처리가 가능한 프로그래밍에 어려움이 있음, 데이터의 처리(또는 집계)를 쉽게 이용하는 방법에는 두 가지가 있음.

첫 번째는 hive와 같이 SQL을 통해 MR을 사용하는 것. Query Engine(쿼리 엔진)이라고 하며, 최근에는 Spark, Presto 등 더 고속의 쿼리 엔진이 개발 되어 사용되고 있음.

두 번째는 외부의 Data Warehouse(데이터 웨어하우스) 제품을 이용하는 것. 분산 스토리지에서 데이터를 추출(Extract)하고 변형하고(Transfrom) 한 후 적재(Load)함. 이 과정을 흔히 ETL이라고 표현

최근에는 ETL이 아닌 ELT 순서로의 처리도 많이 사용되고 있음. Storage의 가격이 워낙 낮아졌기 때문에 우선 저장해 두고 필요에 따라 변환시키는 형태.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaxWLl%2Fbtq0fjeaEXl%2FXAKjg5Tawt9RApmkl7RYo0%2Fimg.jpg)

## 5) Workflow 관리
전체적인 데이터 파이프라인의 동작을 관리하는 것은 Workflow가 그 역할을 함. 정해진 배치 처리를 주기에 맞게 스케쥴링하고 오류가 발생하는 경우는 알림을 보내는 등의 관리의 기술이 필요.

