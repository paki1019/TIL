# 아파치 카프카

아파치 카프카(Apache Kafka)는 여러 대의 분산 서버에서 대량의 데이터를 처리하는 분산 메시징 시스템. 메시지(데이터)를 받고, 받은 메시지를 다른 시스템이나 장치에 보내기 위해 사용. 여러 시스템과 장치를 연결하는 중요한 역할을 함.

![아파치 카프카](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FKMGha%2Fbtq2plbB4VX%2F5PK00QwxkzKKb5j0b35F70%2Fimg.png)

카프카는 대량의 데이터를 **높은 처리량**(high-throughput)과 **실시간**(real-time)으로 취급하기 위한 제품으로 아래 4가지를 실현 가능.

- 확장성: 여러 서버로 '확장(scale out)구성' 할 수 있기 때문에 데이터 양에 따라 시스템 확장이 가능.
- 영속성: 수신한 데이터를 '디스크에 유지'할 수 있기 때문에 언제라도 데이터를 읽을 수 있음.
- 유연성: '연계할 수 있는 제품이 많기' 때문에 제품이나 시스템을 연결하는 허브 역할을 함.
- 신뢰성: '메시지 전달 보증'을 하므로 데이터 분실을 걱정하지 않아도 됨.

현재는 종합 스트림 처리를 위한 플랫폼이 되고 있음.

# 카프카 탄생 배경

## 링크드인 시스템 요구 사항.

카프카는 링크드인 웹사이트에서 생성되는 로그를 처리하여 웹사이트 활동을 추적하는 것을 목적으로 개발됨.(사용자의 페이지 뷰&광고의 이용 등)

링크드인의 목표

1. 높은 처리량으로 실시간 처리.
2. 임의의 타이밍에서 데이터를 읽음.
3. 다양한 제품과 시스템에 쉽게 연동.
4. 메시지를 잃지 않음.

# 카프카로 링크드인 요구 사항 실현하기

실현 수단

1. 메시징 모델과 스케일 아웃형 아키텍처.
2. 디스크로 데이터 영속화.
3. 이해하기 쉬운 API 제공.
4. 전달 보증.

## 메시징 모델과 스케일 아웃.

다음과 같은 요구 사항을 만족시키기 위해서 카프카에서는 메시징 모델을 채용함.

- 1. 높은 처리량으로 실시간 처리.
- 2. 임의의 타이밍에서 데이터를 읽음.
- 3. 다양한 제품과 시스템에 쉽게 연동.

일반적으로 메시징 모델은 다음 세 가지 요소로 구성됨.

- Producer: 메시지 생산자
- Broker: 메시지 수집/전달 역할
- Consumer: 메시지 소비자

![프로듀서, 브로커, 컨슈머](https://baek.dev/assets/images/post/2020/2020_020_001.jpg)

### 큐잉 모델

브로커(Broker) 안에 큐를 준비해, 프로듀서(Producer)에서의 메시지가 큐에 담기고, 컨슈머(Consumer)가 큐에서 메시지를 추출함. 하나의 큐에 대해 여러 컨슈머가 존재함.
이 모델은 컨슈머를 여러 개 준비함으로써 컨슈머에 의한 처리를 확장시킬 수 있으며, 컨슈머가 메시지를 받으면 다른 컨슈머는 메시지를 받을 수 없음.

### 펍/섭 메시징 모델

메시지 생산자인 프로듀서를 '퍼블리셔(Publisher)', 메시지 소비자의 해당 컨슈머를 '서브스크라이버(Subscriber)'라고 함.

퍼블리셔는 서브스크라이버에게 직접 메시지를 보내는 것이 아니라 브로커를 통해 전달함.

퍼블리셔는 누가 그 메시지를 수신하는지 알 수 없고 브로커에 있는 토픽이라고 불리는 카테고리 안에 메시지를 등록함.

서브스크라이버는 여러 개 존재하는 토픽 중 하나를 선택해서 메시지를 받음. 여러 서브스크라이버가 동일한 토픽을 구독하기로 결정한다면, 이 여러 서브스크라이버는 동일한 메시지를 받음. 또한 다른 토픽에서는 다른 메시지를 받을 수 있음.

### 프로듀서/컨슈머 사이에 브로커를 끼우는 장점.

- 프로듀서/컨슈머 모두 접속처를 '하나'로 할 수 있음(수를 줄일 수 있음).

  - 프로듀서는 누구에게 메시지를 전송하면 좋을지 생각할 필요 없이 브로커로 보내기만 하면 됨.
  - 컨슈머도 단순히 브로커에서만 수신하면 됨.
  - 브로커의 존재는 'N X M'의 시스템 구성을 'N + M"으로 만들어 구성을 단순하게 함.

- 프로듀서/컨슈머 증감에 대응할 수 있음(네트워크 토폴로지 변경에 강함).
  - 프로듀서/컨슈머 모두 서로의 존재를 몰라도 되기 떄문에 증감에 유연하게 대응할 수 있음.

## 카프카 메시징 모델

카프카에서는 큐잉 모델에서 실현한 **여러 컨슈머가 분산 처리로 메시지를 소비하는 모델**과 펍/섭 메시징 모델에서 실현한 **여러 서브스크라이버에 동일한 메시지를 전달**하고, **토픽 기반으로 전달 내용을 변경**하는 모델로 되어 있음. 이 모델을 실현하기 위해 '컨슈머 그룹(Consumer Group)'이라는 개념을 도입하여 컨슈머를 확장 구성할 수 있도록 설계하고 있음.

여러 컨슈머가 동일 토픽을 분산하여 메시지를 읽음으로써 처리의 확장성을 담보함. 브로커도 복수 구성으로 동작하도록 되있으며, 결과적으로 전체적 확장 구성을 띄고 있음.

## 디스크로의 데이터 영속화

다음과 같은 요구 사항을 만족시키기 위해서 카프카는 브로커에 보낸 메시지를 디스크에 영속화하고 있음.

- 2. 임의의 타이밍에서 데이터를 읽음.
- 4. 메시지를 잃지 않음. (단, 고장에 의한 최근 메시지 손실 회피 목적은 아님)

미시지 큐에서도 데이터 영속화를 실시하는 제품이 있지만 장기 보존을 가정하지는 않음. 배치 처리의 경우에는 데이터를 일정 기간마다 모아야 할 필요가 있기ㄷ 때문에 데이터를 메모리에서만 유지하는 것은 용량 면에서 불가능. 카프카의 메시지 영속화는 디스크에서 이루어짐. 카프카는 **디스크에 영속화함에도 불구하고 높은 처리량을 제공**한다는 특징이 있음.

속속 들어오는 데이터를 받아들이면서 한 묶음으로 장기 보존을 목적으로 영속화할 수 있기 때문에 카프카를 **스토리지 시스템**으로 간주할 수 있다. 예시로 순서대로 로그를 계속 남기는 커밋 로그를 축적하기 위한 스토리지 시스템 등을 들 수 있음.

## 이해하기 쉬운 API 제공

다음 요구 사항과 관련하여 카프카에서 데이터 출입을 쉽게 하는 API에 대해 설명.

- 3. 다양한 제품과 시스템에 쉽게 연동.

카프카는 프로듀서와 컨슈머를 쉽게 접속할 수 있도록 'Connect API'를 제공함. 각각 이 API를 이용하여 각종 외부 시스템과 접속함. 또한 API를 기반으로 카프카에 접속하기 위한 프레임워크로 Kafka Connect도 제공함.

Kafka Connect와 접속하기 위한 플러그인으로 커넥터(Connector)가 개발되어 있으며 데이터베이스, 키 벨류 스토어, 검색 인덱스, 파일시스템 등의 외부 시스템과 접속할 수 있음.

카프카에 존재하고 있는 데이터를 스트림 처리하는 Streams API를 라이브러리화한 Kafka Streams라는 클라이언트 라이브러리가 준비되어 있음. 사용자는 Kafka Streams 라는 라이브러리를 이용해서 자바 애플리케이션을 만들고, 작동시킬 수 있기 때문에 카프카 입출력에 사용하는 스트림 처리 애플리케이션을 비교적 쉽게 구현할 수 있음.

## 전달 보증

마지막으로 카프카에서 다음 요구 사항을 어떻게 처리하는지 살펴봄.

- 4. 메시지를 잃지 않음.

카프카에서는 'At Most Once', 'At Least Once', 'Exactly Once' 세 가지 수준으로 전달을 보증함.

| 종류          | 개요                      | 재전송 유무 | 중복 삭제 유무 | 비고                                                                           |
| ------------- | ------------------------- | ----------- | -------------- | ------------------------------------------------------------------------------ |
| At Most Once  | 1회는 전달을 시도 해본다. | X           | X              | 메시지는 중복되지 않지만 상실될 수도 있다.                                     |
| At Least Once | 적어도 1회는 전달한다.    | O           | X              | 메시지가 중복될 가능성은 있지만 상실되지는 않는다.                             |
| Exactly Once  | 1회만 전달한다.           | O           | O              | 중복되거나 상실되지도 않고 확실하게 메시지가 도착하지만, 성능이 나오기 힘들다. |

메시지 큐에서는 Exactly Once 수준을 주목적으로 하고 따라서 트랜잭션 관리를 위한 메커니즘이 마련되어 있었다. 그러나 카프카 개발 초기에는 성능을 중시하는 '높은 처리량'을 구현해야 했기 때문에 Exactly Once 수준의 보증은 미루고 최소한 '메시지 분실 방지'를 위한 At Least Once 수준으로만 전달을 보증했음.

At Least Once를 실현하기 위해 Ack와 오프셋 커밋(Offset Commit)이라는 개념을 도입하고 있음. Ack는 브로커가 메시지를 수신했을 때 프로듀서에게 수신 완료했다는 응답을 뜻함. 이것을 이용해 프로듀서가 Ack를 받지 못한 경우에 재전송해야 한다고 판단할 수 있음.
![프로듀서에 Ack 반환](https://baek.dev/assets/images/post/2020/2020_020_002.jpg)

또한 컨슈머가 브로커로부터 메시지를 받을 때 컨슈머가 어디까지 메시지를 받았는지를 관리하기 위한 오프셋이 있으며, 이를 이용한 전달 범위 보증의 구조를 오프셋 커밋이라고 함. 오프셋 커밋은 메시지를 받아 정상적으로 처리를 완료한 다음 오프셋을 업데이트함으로써 어딘가 잘못된 문제로 메시지를 재전송할 때도 어디서부터 재전송하면 되는지 판단할 수 있다.
![컨슈머에서 읽은 기록을 오프셋 커밋으로 브로커에 남김](https://baek.dev/assets/images/post/2020/2020_020_003.jpg)

Exactly Once 수준에서는 구체적으로 쌍방간의 실현이 모두 필요한데, 첫 번째는 프로듀서와 브로커의 상호 교환 사이에서, 그리도 두 번째는 브로커와 컨슈머의 상호 교환 사이에서 필요함.

프로듀서와 브로커의 상호 교환 사이를 살펴보면 양쪽 모두에서 시퀸스 번호를 관리해 중복되는 실행을 제거하는 방법을 사용함.

![카프카가 상류 시스템에서 중복 메시지를 제거하는 방법](https://t3guild.files.wordpress.com/2020/04/7041a-image-15.png)

브로커와 컨슈머 간 교환에 있어서는 컨슈머에 대해 트랜잭션 범위를 해석하고, 트랜잭션 중단 시 중단까지의 처리를 파기하는 기능이 있음.

![카프카가 할 시스템에서 트랜잭션 중단을 해석하는 모습](https://t3guild.files.wordpress.com/2020/04/aa139-image-16.png)
